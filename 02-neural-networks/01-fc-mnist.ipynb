{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Künstliche Neuronale Netze\n",
    "In diesem Notebook wird ein einfaches künstliches Neuronales Netz zur Klassifizierung von handgeschriebenen Zahlen implementiert und demonstriert. Die Deep-Learning Bibliothek [Keras](https://keras.io/) wird genutzt, um für Einstieg in die Programmierung auf einer hohen Abstraktionsebene zu ermöglichen. Keras setzt auf dem bekannten Deep Learning Framework [TensorFlow](https://tensorflow.org) auf.\n",
    "\n",
    "![MNIST dataset of handwritten digits](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "Der [MNIST-Datensatz](http://yann.lecun.com/exdb/mnist/) ist ein sehr beliebtes Beispiel, um anhand eines einfachen Klassifizierungsproblems Machine Learning Techniken zu demonstrieren. Die 60000 Beispiele dieses Datensatzes sind Bilder von handgeschriebenen Zahlen in der Auflösung 28x28-Pixel und den dazugehörigen beschreibenden Labels (z.B. \"2\", \"9\", ...). Aufgrund der begrenzten Rechenkapazität wird werden die Modelle hier mit einer Teilmenge von 2000 Bildern trainiert und mit 1000 Bildern getestet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmbiblioteken importieren\n",
    "Neben unterschiedlichen Modulen der Keras-Bibliothek wird `matplotlib` für die Visualisierungen importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz laden\n",
    "Keras bringt eine [Reihe von Datensätzen](https://keras.io/datasets/) zum Ausprobieren der Bibliothek mit. Mit einem einzigen Funktionsaufruf kann wie folgend der Test- und Trainingsdatensatz in entsprechende Varablen geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten überprüfen\n",
    "Mit Ausführen der nächsten Codezelle werden probeweise neun handgeschriebene Zahlen aus dem Datensatz mitsamt der dazugehörigen Labels ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(x_train[0:9], y_train[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorverarbeiten\n",
    "Um die zweidimensionalen Bilder in ein einfaches neuronales Netz geben zu können, müssen diese in Vektoren umgeformt werden. Aus 28x28 Pixel Bildern werden 784-dimensionale Vektoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Klassen festlegen\n",
    "num_classes = 10\n",
    "num_train_images = 2000\n",
    "\n",
    "x_train = x_train[0:num_train_images].reshape(-1, 784).astype('float32')\n",
    "x_test = x_test.reshape(-1, 784).astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Kodieren der Klassenlabels nach dem One-Hot Prinzip\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)[0:num_train_images]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellarchitektur\n",
    "\n",
    "![Netzarchtektur für MNIST-Klassifizierung](https://3.bp.blogspot.com/-mDyzBzA4btg/V4_Z0f2mc7I/AAAAAAAAE3M/dtU8hT661fQWtnRC_JvIH_4qifQomZ4PACLcB/s1600/MNIST_neuralnet_image.png)\n",
    "\n",
    "In der folgenden Codezelle die Architektur des neuronalen Netzes definiert. In dem `Sequential(...)`-Funktionsaufruf befindet sich eine Liste von Anweisungen, die von Input bis Output das Netz konstruieren. `Dense(100)` bedeutet beispielsweise, dass eine Schicht mit 100 Neuronen in das Modell eingefügt wird. Der darauffolgende Aufruf `Activation('sigmoid')` bedeutet, dass die Sigmoid-[Aktivierungsfunktion](https://keras.io/activations/) genutzt wird.  \n",
    "\n",
    "Die `softmax`-Aktivierungsfunktion am Ende des Modells normiert die Ausgabewerte der letzten Neuronenschicht, sodass diese in der Summe 1 ergeben - so kann das Ergebnis als Wahrscheinlichkeit interpretiert werden. Jedes Output-Neuron steht für eine Klasse der handgeschriebenen Zeichen.\n",
    "\n",
    "Das Modell kann beliebig erweitert und verändert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_shape=(784,)),\n",
    "    Activation('sigmoid'),\n",
    "    #Dense(100),\n",
    "    #Activation('sigmoid'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgenden Aufruf `model.compile(...)` weist dem Modell eine Fehlerfunktion (`loss`) und einen Optimizer (vgl. Gradient Descent) zu. Nach Ausführen der folgenden Codezeile kann das Modell trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegebenenfalls bereits vorhandene Gewichte löschen.\n",
    "model.reset_states()\n",
    "\n",
    "# Optimizer und Loss festlegen und das Modell kompilieren.\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell trainieren\n",
    "Nun wird die Anzahl der Durchläufe durch den Datensatz zum Trainieren festgelegt. Das Ausführen der nächsten Zelle startet den Trainingsvorgang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Iterationen durch den kompletten Datensatz (Epochs)\n",
    "num_epochs = 10\n",
    "\n",
    "# Trainingsvorgang des Modells mit einer batch-size von 32 starten\n",
    "training_history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=32, validation_data=(x_test[0:1000], y_test[0:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell evaluieren\n",
    "Es kann hilfreich sein, die Entwicklung der Fehlermetriken über den Trainingsverlauf zu beobachten. Während die Fehlermetrik `loss` den Durchschnittlichen Fehler während des Trainings auf dem Trainingsdatensatz beschreibt, wird der sogenannte _Validation-Loss_ nach jedem Interation durch den Datensatz (_Epoch_) berechnet: `val_loss` ist der Fehler auf einer Teilmenge des Test-Datensatzes. Konvergiert die Auswertung der Trainings-Lossfunktion gegen 0, ist die gesuchte Funktion für die gewählte Netzarchitektur lernbar. Auch die Entwicklung des Validation-Loss ist wichtig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_history.history['loss'])\n",
    "plt.plot(training_history.history['val_loss'])\n",
    "plt.title('Loss-Entwicklung über den Trainingsverlauf')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimente\n",
    "* Was könnte passieren, wenn der Parameter `batch_size` zu klein bzw. zu groß gewählt ist?\n",
    "* Welches Problem könnte vorliegen, wenn in obiger Abbildung die blaue Kurve des Trainings Loss-Verlaufs gegen 0 konvergiert, die orange Validation-Loss Kurve aber nach vielen viele Datensatz-Iterationen (`epochs`) nach oben ausschlägt?\n",
    "* Die während der Vorverarbeitung definierte Variable `num_train_images` gibt die Anzahl der für das Training zu verwendenden Beispiele an. Wie verhält sich die Genauigkeit der Klassifizierung, wenn die Anzahl verringert wird?\n",
    "* In der Modellarchitektur in der Funktion `model.compile` wird `rmsprop` als Optimizer gesetzt. Die Keras-Dokumentation führt eine [Liste von Optimizern](https://keras.io/optimizers/). Welche Auswirkungen hat die Wahl des Optimizers auf den Trainingsverlauf bzw. die Ergebnisse?\n",
    "* Im ersten Codeblock der Modellarchitektur befinden sich zwei auskommentierte Zeilen, die mit einer Raute beginnen. Werden die Rauten dieser beiden Zeilen entfernt, vergrößert sich das Modell um eine weitere Schicht. Nun kann die Zelle und alle darauffolgenden Zellen erneut ausgeführt werden. Verändert sich die Genauigkeit des Modells auf dem Testdatensatz? Auch die Anzahl der Neuronen (`100`) der Ebenen und die Aktivierungsfunktion der Neuronen kann an dieser Stelle geändert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Links\n",
    "\n",
    "[TensorFlow Playground](https://playground.tensorflow.org/) ist eine Browserbasierte Simulation eines künstlichen neuronalen Netzes. Es können verschiedene Datensätze ausgewählt, die Modellarchitektur angepasst und der Trainingsprozess überwacht werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
