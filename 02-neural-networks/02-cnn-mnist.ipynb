{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "In diesem Codebeispiel wird das neuronale Netz aus dem vorherigen Beispiel um Convolutions erweitert. Statistische Abhängigkeiten zwischen Bildern können mit dieser Technik modelliert werden.\n",
    "\n",
    "Analog zu dem biologischen Konzept von rezeptiven Feldern werden in CNNs mehrere Bildpunkte auf einmal betrachtet. 3x3 Pixel Filtermatrizen werden über das zu verarbeitende Bild geschoben und mit jedem 3x3-Bildbereich verrechnet (siehe Abbildung). Die so entstandenen _activation maps_ werden weiter durch das CNN gereicht und dabei so transformiert, dass auf der letzten Neuronenschicht eine Klassenwahrscheinlichkeit abgelesen werden kann.\n",
    "\n",
    "![Convolutions](https://upload.wikimedia.org/wikipedia/commons/4/4f/3D_Convolution_Animation.gif)\n",
    "\n",
    "## Programmbibliotheken einbinden\n",
    "Wie gewohnt werden alle benötigten Module und Klassen importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST-Datensatz laden\n",
    "Der bekannte MNIST handwritten digits Datensatz wird von `keras.datasets` geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz vorverarbeiten\n",
    "Im ersten Praxisblock wurde das zu verarbeitende Bild für den Input in das Netz durch den _Flatten_-Operator in einen 784-dimensionalen Vektor verwandelt. Bei der Bildverarbeitung mit CNNs geschieht dies nicht, da die Pixel für die Verrechnung mit den Filtermatrizen in ihrer ursprünglichen Anordnung vorliegen müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegen der Anzahl möglicher Labels\n",
    "num_classes = 10\n",
    "\n",
    "# Festlegen der Anzahl für das Training genutzter Bilder\n",
    "num_train_images = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandeln der Bilddaten in 28x28x1 Pixel (1-Kanal Graustufe)\n",
    "x_train = x_train[0:num_train_images].reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalisierung der Werte von 0 bis 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Konvertieren der Labels in das One-Hot Format\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)[0:num_train_images]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellarchitektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states() \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test[0:500], y_test[0:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell evaluieren\n",
    "Wie bereits in dem ersten Beispiel kann die Qualität des trainierten Modells mithilfe des Test-Datensatzes und den Kurven der Loss-Entwicklung beurteilt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_history.history['loss'])\n",
    "plt.plot(training_history.history['val_loss'])\n",
    "plt.title('Loss-Entwicklung über den Trainingsverlauf')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Links\n",
    "\n",
    "[3D visualization of a CNN](http://scs.ryerson.ca/~aharley/vis/conv/): Die Fakultät Computer Science der Universität Ryerson, Kanada hat eine interaktive 3D-Visualisierung entwickelt, um die Funktionsweise von Convolutional Neural Networks nachvollziehbar zu machen.\n",
    "\n",
    "[The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/) ist eine anschauliche Visualisierung, die zeigt, welche Muster CNNs lernen und wie diese Muster interpretierbar gemacht werden können.\n",
    "\n",
    "[Google Colab: Fashion MNIST](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb): Das in dieser Aufgabe gelöste MNIST-Beispiel gilt teilweise als abgegriffen und mit heutigen Technologien zu einfach lösbar. Fashion-MNIST ist ein Datensatz zur Klassifizierung von Kleidungsstücken. Das Notebook hierzu läuft auf Google Colab, einer von Google bereitgestellten Jupyter Notebook Umgebung mit kostenlosen GPU-Instanzen.\n",
    "\n",
    "[Seedbank](https://research.google.com/seedbank/seeds?keyword=mlbasics) ist eine Sammlung von interaktiven Jupyter-Notebooks zu den unterschiedlichsten ML- und Deep-Learning-Themen. Alle Notebooks laufen auf Google Colab, weshalb auch hier ein Google Account notwendig ist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
